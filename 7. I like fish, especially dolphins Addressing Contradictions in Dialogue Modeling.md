## 논문
- 제목 : I like fish, especially dolphins Addressing Contradictions in Dialogue Modeling
- 원본 : [https://arxiv.org/abs/2012.13391](https://arxiv.org/abs/2012.13391)
- 요약 : [PDF](summary/7.%20I%20like%20fish%20especially%20dolphins%20Addressing%20Contradictions%20in%20Dialogue%20Modeling.pdf)
<br>


## 참여자
이정훈, 구선민, 김소연, 남궁민상, 류지은
<br><br>


## 토론
- Q1. utterance라는 단어가 계속 등장하는데 이게 무엇인가요? 인풋 데이터의 기본 단위인 것 같은데 어떤 형태의 데이터인지 감이 안 잡히네요. (chat 하나인가요?)

  >- A1. 저는 Figure 1 기준으로 말뭉치 하나 하나를 utterance라고 생각했습니다.(Figure2 도 참고)

  >- A1. 한국어로 '발화'라는 뜻인데, 뜻은 소연님께서 말씀하신게 맞는 것 같구요. 대화를 하는 것이 spoken language로 봐서, utterance라고 한게 아닐까 싶네요. 
  > 한 문장으로 볼 수도 있고, 두 문장으로 볼 수도 있고.. 챗봇 모델로 치면 말풍선 하나가 아닌가 싶습니다. 

<br>

- Q2. 만약에 대부분의 사람들이 잘못 알고 있는 지식을 챗봇이 올바른 지식으로 답변해서(ex. A는 사과이나 대부분 사람들은 바나나로 알고 있음, A에 대해 질문했을 때 챗봇이 바나나라고 대답) consistency 없다고 느꼈으나 실제 지식적 측면으로 맞는 경우에는 어떻게 다뤄야 할까요?

  >- A2. 이는 챗봇의 목적이 무엇인지에 따라 달라질 것 같아요! 정보나 실질적인 편의 제공의 목적이 강한 챗봇의 경우에는 지식에 좀 더 포커스를 둬야 할 것이고, 이루다처럼 캐주얼한 대화를 주 목적으로 삼는다면 consistency에 주안점을 두지 않을까 싶네요. 
  > 지식 부합 여부에 대한 scoring function에 비중을 얼마나 줄지를 통해 판단의 우선순위를 조절할 수 있지 않을까요?

<br>

- Q3. 사람다운 답을 한다는 것은 뭔가 배경지식이 비슷하다는 가정하에서 사용자가 원하는 답을 내보내는 것 같다는 것이라는 생각이 드는데 실제 서비스에서 새로운 정보에 대한 업데이트는 어떻게 하나요? 

  >- A3. 특정 주기 혹은 사용자 input data에 대한 모델의 예측값이 기존의 예측 boundary에서 많이 벗어날 경우에 대해 서버로 (실시간 혹은 일정 주기로) 해당 데이터를 보내면, 전체 유저들에 대해 그런 데이터를 일정 수준 이상이 서버에서 모였을 때 업데이트해서 다시 모델을 배포하는 식이 아닐까요? 운용하는 예측 모델이 몇개냐, 서비스 특성에 따라 폴리시가 다를 것 같긴합니다.

<br>

- Q4. dialogue에서 out-of-distribution 이라함은 트레이닝 데이터셋에서 한번도 다루지 않은 topic?에 대해 대화하는 것을 의미하나요? 

  >- A4. 논문에서의 'especially for OOD scenarios which are often the case when incorporating NLU modules into NLG systems, since intermediate in-domain data are scarce.' 부분을 보면 소연님 설명이 맞는 것 같습니다. 트레이닝은 맛집(in-domain)으로 시키고, 테스트는 스포츠(out of domain)에 대해서 한다던가..

<br>

- -Q5. Diagloue contradiction detector 유형 중 structued utternace-based approach에서 "Since the reasoning crucially depends on the last utterance,"  라고 말을 하는 이유는 dataset의 remove contradicting turn(RCT)라는 contradiction의 낌새가 보이면 마지막 utterance 제외하고 다 지워버리는 과정(이것도 제가 이해한게 맞는지..) 이 들어가서 그런것인가요..? 이 과정이 auxiliary test set을 구축하는데만 사용되는걸로 처음 이해했었어서요.

  >- A5. 저는 last utterance가 판단의 대상이 되는 utterance (u_n)이라고 이해하고, 어느 정도 당연하다고 생각했어요. consistent한지 아닌지 판단하는 대상이 뭔지가 판단 과정에 있어 큰 영향을 줄 거라는 건 좀 당연하게 느껴져서...? 근데 소연님 질문을 읽고보니 그래서 last speaker의 대화로만 이루어진 *S*를 이용한다는 건 좀 비약으로 보이네요ㅠ

<br>

- Q6. 결과 분석 중 structued utterance based approach가 더 강인하고 transferable하다고 합니다. 그 이유가 Figure3의 4가지 실험 중에 unstructued 경우 Human-bot, RCT에서 굉장히 낮은 성능이 나오고, 이 현상은 'overfitting on superficial pattern'일 가능성이 높다고 합니다. 제가 느끼기에 unstructured apporach가 훨씬 덜 정제된 방식으로 추론하는 것 같은데, overfitting on superficial pattern이 NLP에서 overfitting 말고 어떤 의미를 가지는지/ 그리고 그 현상이 왜 unstructured에서 더 발현되는 것으로 보인다고 해석한 것일까요?

  >- A6. 제 생각에는 unstructured 방법이 structured와 비교해 한번에 입력되는 값이 더 많습니다. unstrucutred 방법은 모든 문장을 하나로 합쳐 입력되기 때문에 피상적인 패턴에 대해 과적합할 수 있다고 표현한 것 같습니다. 이런 경우 입력값에 실제 정답과는 거리가 먼 데이터들이 포함되어 있을 가능성이 비교적 높고 그것을 학습하기 때문에 그런 것 같습니다.

<br>

- Q7. Table 6에서 DECODE와 human judgement가 얼추 비슷한 성능을 보이는데, DECODE Re-ranking의 Top-k는 비율 차이가 유독 크네요. 이 결과를 어떻게 설명해야 할까요?

  >- A7. 답변

<br>

- Q8. 모델의 robustness를 알아보기 위해 A2T, RCT 등의 추가적인 테스트셋을 만들었는데, 혹시 이런 데이터셋은 없나요? 언뜻 보기엔 inconsistent하지만 추가적인 정보가 주어진다면 consistent한 대화들이 있을 것 같아요. 이를 테면,

  - A: 내가 가장 좋아하는 숫자는 42야
  - B: 너 *히치하이커*의 팬이구나! (여기까지는 언뜻 봤을 때 inconsistent)
  - A: 응? 그게 뭐야?
  - B: 유명한 소설인데 거기서 42가 중요하게 나오거든. 그래서 42를 좋아하는 줄 알았지.

  사전 지식이 관여되어 있거나 고유명사/다의어/동음이의어에 대한 대화, 모호한 문장의 경우 이와 같은 일이 심심찮게 있을 것 같은데요. 이런 경우를 다룬 auxiliary test set은 없을까요?

  >- A8 (정훈). 위에서 언급해주신 사전 지식이 따로 정제되어 있는 대화 데이터는 보지 못한 것 같습니다. 보통 데이터 안에 자동적으로 사전 지식이 포함되어 있다고 가정하고 진행하는 경우를 많이 본 것 같습니다. 만약 사전 지식의 도메인이 좀 특별한 도메인이면 애초에 학습, 검증, 테스트 데이터 셋 속성을 통일하고 가는 경우가 많은 것 같습니다. 

위에서 말씀해주신 고유명사/다의어/동음이의어 같은 경우도 데이터 안에 포함되어 있다고 많이 가정하는 편이고 최근 NLP 모델이 동음이의어/다의어 같은 것들을 주변 단어들을 통해 잘 분리하기 때문에 큰 문제는 없을 것 같습니다.

<br>

- Q9. Human-Bot Test Set 항목에서 unlikelihood trained models라는게 나오는데 흥미롭네요. 혹시 짤막하게 설명해주실 수 있는 분 계실까요?

  >- A9. 제 생각에는 generation task에서 loss를 unlikelihood loss를 사용한 모델을 지칭하는 것 같습니다. 
  > unlikelihood : 언어모델이 실제 사람이 사용한 데이터셋의 분포와 비교하여 더 많이 사용하는 것들에 대해 확률 분포를 낮춤으로써 적절한 횟수의 사용을 하도록 하는게 목표. unlikelihood의 log안에 괄호를 최대화하여 c의 확률 분포를 낮추는게 목표
  >  논문 : [https://arxiv.org/pdf/1911.03860.pdf](https://arxiv.org/pdf/1911.03860.pdf)
